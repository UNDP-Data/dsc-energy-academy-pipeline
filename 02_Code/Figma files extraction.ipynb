{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyGithub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process multiple files separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file for Module 1 :\n",
      "Frames data has been exported to figma_frames_XN57QSSgnI4exbB2OTK1QM.csv\n",
      "Frames data has been exported to figma_frames_XN57QSSgnI4exbB2OTK1QM.json\n",
      "Processing file for Module 2 :\n",
      "Frames data has been exported to figma_frames_5cH2oMyNQPZ1w9fUPM9Mfe.csv\n",
      "Frames data has been exported to figma_frames_5cH2oMyNQPZ1w9fUPM9Mfe.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "API_TOKEN = 'add figma token'\n",
    "FILE_KEYS = ['add first file key', 'add second file key']  # Ensure MODULE is part of the file key or name\n",
    "\n",
    "# Figma API URL template\n",
    "FIGMA_API_URL_TEMPLATE = 'https://api.figma.com/v1/files/{}'\n",
    "\n",
    "# Headers for the API request\n",
    "headers = {\n",
    "    'X-Figma-Token': API_TOKEN\n",
    "}\n",
    "\n",
    "#  Function to determine the module (section) number from the file name or URL (e.g., MODULE1 -> 1)\n",
    "def get_section_number(file_name):\n",
    "    match = re.search(r'MODULE(\\d+)', file_name, re.IGNORECASE)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Main processing function to handle multiple files\n",
    "def process_figma_files(file_keys):\n",
    "    for file_key in file_keys:\n",
    "        # Here we assume that the module name is included in the file_key itself, such as 'XN57QSSgnI4exbB2OTK1QM/MODULE1'\n",
    "        # If the URL or file name contains the module information, extract it\n",
    "        section_number = get_section_number(file_key)  # Extract the module number dynamically\n",
    "        \n",
    "        if section_number is None:\n",
    "            section_number = 0  # Default to 0 if no module is found in the file_key\n",
    "        print(f\"Processing file for Module {section_number} :\")\n",
    "\n",
    "        # Proceed to fetch the data from Figma API\n",
    "        response = requests.get(FIGMA_API_URL_TEMPLATE.format(file_key.split('/')[0]), headers=headers)  # Use only the actual file key part for the API\n",
    "        if response.status_code == 200:\n",
    "            file_data = response.json()\n",
    "            if 'document' in file_data:\n",
    "                # Extract frames for the current file using the section number\n",
    "                frames = extract_frames(file_data['document']['children'], section_number)\n",
    "\n",
    "                # Sort frames by their position on the canvas (first by y, then by x)\n",
    "                frames.sort(key=lambda f: (f.get('y', float('inf')), f.get('x', float('inf'))))\n",
    "\n",
    "                # Generate unique filenames for each file\n",
    "                csv_filename = f'figma_frames_{file_key.split(\"/\")[0]}.csv'  # Using only the file key part for the filename\n",
    "                json_filename = f'figma_frames_{file_key.split(\"/\")[0]}.json'\n",
    "\n",
    "                # Export the frames data to a CSV file\n",
    "                save_to_csv(frames, csv_filename)\n",
    "                print(f\"Frames data has been exported to {csv_filename}\")\n",
    "\n",
    "                # Export the frames data to a JSON file\n",
    "                save_to_json(frames, json_filename)\n",
    "                print(f\"Frames data has been exported to {json_filename}\")\n",
    "            else:\n",
    "                print(f\"Warning: 'document' key not found in file with key {file_key}. Skipping this file.\")\n",
    "        else:\n",
    "            print(f\"Error: Failed to fetch data for file key {file_key}. Status code: {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "\n",
    "# Function to recursively extract frames from the file data\n",
    "def extract_frames(nodes, section_number=1, subsection_number=None):\n",
    "    frames = []  # Initialize a new list for each call to avoid data mix-up\n",
    "    for node in nodes:\n",
    "        if node['type'] == 'FRAME':\n",
    "            processed_frame = process_frame(node, section_number, subsection_number)\n",
    "            if processed_frame:  # Only add if the frame was successfully processed\n",
    "                frames.append(processed_frame)\n",
    "        if 'children' in node:\n",
    "            frames.extend(extract_frames(node['children'], section_number, subsection_number))  # Collect all child frames\n",
    "    return frames\n",
    "\n",
    "# Function to save the frames data to a CSV file\n",
    "def save_to_csv(frames, filename):\n",
    "    # Assign the correct column number after sorting\n",
    "    for i, frame in enumerate(frames):\n",
    "        frame['Column'] = i + 1\n",
    "        frame.pop('x', None)  # Remove 'x' after sorting\n",
    "        frame.pop('y', None)  # Remove 'y' after sorting\n",
    "\n",
    "    # Specify the CSV column headers\n",
    "    csv_columns = ['Section', 'Subsection', 'Section Title', 'Template Type', 'Column', 'Text', 'id']\n",
    "    \n",
    "    # Define the path to save the CSV file in the \"01_Results\" folder\n",
    "    results_folder = os.path.join('..', '01_Results')\n",
    "    os.makedirs(results_folder, exist_ok=True)  # Ensure the folder exists\n",
    "\n",
    "    # Full path to the CSV file\n",
    "    csv_path = os.path.join(results_folder, filename)\n",
    "    \n",
    "    # Open the CSV file for writing\n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write each frame's data to the CSV file\n",
    "        for frame in frames:\n",
    "            writer.writerow(frame)\n",
    "\n",
    "# Function to save the frames data to JSON files\n",
    "def save_to_json(frames, filename):\n",
    "    # Assign the correct column number after sorting\n",
    "    for i, frame in enumerate(frames):\n",
    "        frame['Column'] = i + 1\n",
    "        frame.pop('x', None)  # Remove 'x' after sorting\n",
    "        frame.pop('y', None)  # Remove 'y' after sorting\n",
    "    \n",
    "    # Define the path to save the JSON file in the \"00_API\" folder\n",
    "    api_folder = os.path.join('..', '00_API')\n",
    "    os.makedirs(api_folder, exist_ok=True)  # Ensure the folder exists\n",
    "\n",
    "    # Full path to the JSON file\n",
    "    json_path = os.path.join(api_folder, filename)                   \n",
    "\n",
    "    # Convert the frames list to a JSON structure and save to file\n",
    "    with open(json_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(frames, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Execute the main function with the list of file keys\n",
    "process_figma_files(FILE_KEYS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of multiple images and graphics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames data has been exported to 00_API folder ../00_API\\figma_frames_XN57QSSgnI4exbB2OTK1QM.json\n",
      "Frames data has been exported to 00_API folder ../00_API\\figma_frames_5cH2oMyNQPZ1w9fUPM9Mfe.json\n"
     ]
    }
   ],
   "source": [
    "# GitHub base URLs for images and graphics\n",
    "IMAGE_BASE_URL = 'https://raw.githubusercontent.com/UNDP-Data/dsc-energy-academy-pipeline/main/03_Inputs/images/'\n",
    "GRAPHIC_BASE_URL = 'https://raw.githubusercontent.com/UNDP-Data/dsc-energy-academy-pipeline/main/03_Inputs/graphics/'\n",
    "\n",
    "# Headers for the API request\n",
    "headers = {\n",
    "    'X-Figma-Token': API_TOKEN\n",
    "}\n",
    "\n",
    "# Function to determine the appropriate header tag based on font size\n",
    "def determine_header_tag(font_size):\n",
    "    if font_size >= 32:\n",
    "        return 'h1'\n",
    "    elif 24 <= font_size < 32:\n",
    "        return 'h2'\n",
    "    elif 20 <= font_size < 24:\n",
    "        return 'h3'\n",
    "    elif 16 <= font_size < 20:\n",
    "        return 'h4'\n",
    "    elif 14 <= font_size < 16:\n",
    "        return 'h5'\n",
    "    else:\n",
    "        return 'h6'\n",
    "\n",
    "# Function to determine the module (section) number from the file name (e.g., MODULE1 -> 1)\n",
    "def get_section_number(file_name):\n",
    "    match = re.search(r'MODULE(\\d+)', file_name, re.IGNORECASE)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Function to look for image or graphic labels and return the corresponding URLs\n",
    "def extract_image_or_graphic_url_from_text(text, module_number):\n",
    "    image_urls = []\n",
    "\n",
    "    # Check for image references in the format image_[number]:\n",
    "    image_references = re.findall(r'image_(\\d+):', text)\n",
    "    for image_number in image_references:\n",
    "        image_url = f\"{IMAGE_BASE_URL}image_{image_number}.png\"\n",
    "        image_urls.append(image_url)\n",
    "\n",
    "    # Check for graphic references in the format graphic_[number]:\n",
    "    graphic_references = re.findall(r'graphic_(\\d+):', text)\n",
    "    for graphic_number in graphic_references:\n",
    "        graphic_url = f\"{GRAPHIC_BASE_URL}Module_{module_number}/graphic_{graphic_number}.png\"\n",
    "        image_urls.append(graphic_url)\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "# Function to check for image nodes and return image URLs\n",
    "def extract_image_from_frame(frame):\n",
    "    # Check if the frame contains an image node\n",
    "    image_nodes = [node for node in frame['children'] if node['type'] == 'IMAGE']\n",
    "    \n",
    "    if image_nodes:\n",
    "        # Dynamically assign an image number or ID from the node name\n",
    "        # Assuming the image follows the \"image_[number]\" convention\n",
    "        image_number = frame['name'].split(' ')[-1]  # Extracting the number from the frame name\n",
    "        image_url = f\"{IMAGE_BASE_URL}image_{image_number}.png\"\n",
    "        return image_url\n",
    "    return None\n",
    "\n",
    "# Function to process a frame and extract relevant information, including image URLs and subsections\n",
    "def process_frame(frame, section_number, subsection_number, file_key):\n",
    "    if 'absoluteBoundingBox' not in frame:\n",
    "        print(f\"Warning: 'absoluteBoundingBox' missing for frame '{frame.get('name', 'Unnamed')}'. Skipping this frame.\")\n",
    "        return None\n",
    "\n",
    "    frame_data = {\n",
    "        'Section': section_number,\n",
    "        'Subsection': subsection_number,\n",
    "        'Section Title': frame['name'],\n",
    "        'Template Type': 'Photo' if 'IMAGE' in [node['type'] for node in frame['children']] else 'Text',\n",
    "        'Column': 0,\n",
    "        'Text': '',\n",
    "        'id': '',\n",
    "        'image_url': []  # Placeholder for image URLs\n",
    "    }\n",
    "\n",
    "    # Check for image nodes in the frame\n",
    "    image_url = extract_image_from_frame(frame)\n",
    "    if image_url:\n",
    "        frame_data['image_url'].append(image_url)\n",
    "    else:\n",
    "        # If no image node, check if the text contains \"image_[number]:\" or \"graphic_[number]:\"\n",
    "        for node in frame['children']:\n",
    "            if node['type'] == 'TEXT':\n",
    "                font_size = node.get('style', {}).get('fontSize', 14)\n",
    "                header_tag = determine_header_tag(font_size)\n",
    "                text = node['characters']\n",
    "                \n",
    "                # Add text to the frame data\n",
    "                frame_data['Text'] += f'<{header_tag}>{text}</{header_tag}>'\n",
    "\n",
    "                # Extract image or graphic URLs from the text\n",
    "                image_urls = extract_image_or_graphic_url_from_text(text, section_number)\n",
    "                if image_urls:\n",
    "                    frame_data['image_url'].extend(image_urls)\n",
    "                else:\n",
    "                    frame_data['image_url'].append(\"Image URL not found\")\n",
    "\n",
    "    return frame_data\n",
    "\n",
    "# Function to recursively extract frames from the file data\n",
    "def extract_frames(nodes, file_name, section_number, subsection_number=None):\n",
    "    frames = []\n",
    "    for node in nodes:\n",
    "        if node['type'] == 'FRAME':\n",
    "            # If the frame contains 'Subsection', update the subsection number\n",
    "            if 'Subsection' in node['name']:\n",
    "                subsection_number = int(re.search(r'\\d+', node['name']).group())\n",
    "                continue\n",
    "\n",
    "            # Process the frame\n",
    "            processed_frame = process_frame(node, section_number, subsection_number, file_name)\n",
    "            if processed_frame:\n",
    "                frames.append(processed_frame)\n",
    "\n",
    "        # If there are children, recurse into them\n",
    "        if 'children' in node:\n",
    "            frames.extend(extract_frames(node['children'], file_name, section_number, subsection_number))\n",
    "    return frames\n",
    "\n",
    "# Function to save the frames data to JSON files\n",
    "def save_to_json(frames, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(frames, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Function to process a single Figma file with retry and delay\n",
    "def process_single_file(file_key, delay=2, max_retries=3):\n",
    "    retries = 0\n",
    "    success = False\n",
    "    while retries < max_retries and not success:\n",
    "        try:\n",
    "            response = requests.get(FIGMA_API_URL_TEMPLATE.format(file_key), headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                file_data = response.json()\n",
    "                file_name = file_data['name']\n",
    "                section_number = get_section_number(file_name)\n",
    "\n",
    "                if 'document' in file_data:\n",
    "                    frames = extract_frames(file_data['document']['children'], file_name, section_number)\n",
    "                    frames.sort(key=lambda f: (f.get('y', float('inf')), f.get('x', float('inf'))))\n",
    "\n",
    "                    json_filename = os.path.join('../00_API', f'figma_frames_{file_key}.json')\n",
    "                    save_to_json(frames, json_filename)\n",
    "                    print(f\"Frames data has been exported to 00_API folder {json_filename}\")\n",
    "                    success = True  # Mark success to exit the retry loop\n",
    "                else:\n",
    "                    print(f\"Warning: 'document' key not found in file with key {file_key}. Skipping this file.\")\n",
    "                    success = True  # No need to retry\n",
    "            elif response.status_code == 429:  # Rate limiting error\n",
    "                print(f\"Rate limit hit. Retrying after {delay} seconds...\")\n",
    "                retries += 1\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"Error: Failed to fetch data for file key {file_key}. Status code: {response.status_code}\")\n",
    "                retries += 1\n",
    "                time.sleep(delay)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file key {file_key}: {e}\")\n",
    "            retries += 1\n",
    "            time.sleep(delay)\n",
    "        if retries == max_retries:\n",
    "            print(f\"Max retries reached for file key {file_key}. Skipping this file.\")\n",
    "\n",
    "# Function to process Figma files sequentially with delay\n",
    "def process_figma_files_sequential(file_keys, delay_between_requests=2):\n",
    "    for file_key in file_keys:\n",
    "        process_single_file(file_key, delay=delay_between_requests)\n",
    "\n",
    "# Execute the main function with the list of file keys sequentially\n",
    "process_figma_files_sequential(FILE_KEYS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
