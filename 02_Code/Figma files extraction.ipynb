{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv # library to read key-value pairs from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nececessary libraries\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import time  # For adding delays between requests\n",
    "from dotenv import load_dotenv # for accessing the api key in .env file\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "API_TOKEN = os.getenv('FIGMA_API_KEY')\n",
    "\n",
    "# Figma API URL template\n",
    "FIGMA_API_URL_TEMPLATE = 'https://api.figma.com/v1/files/{}'\n",
    "\n",
    "# Headers for the API request\n",
    "headers = {\n",
    "    'X-Figma-Token': API_TOKEN\n",
    "}\n",
    "\n",
    "# Base URL for the GitHub repository to fetch inputs (images and graphics)\n",
    "GITHUB_BASE_URL = 'https://raw.githubusercontent.com/UNDP-Data/dsc-energy-academy-pipeline/main/03_Inputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process multiple files sequentially & Extract images and graphics URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to extract the file name as the section from the URL\n",
    "# def get_file_name_from_url(url):\n",
    "#     # Extract the part after '/design/' and before the first '?' (if present)\n",
    "#     match = re.search(r'/design/[A-Za-z0-9]+/([^/?]+)', url)\n",
    "#     if match:\n",
    "#         # Return the full file name (section name)\n",
    "#         return match.group(1)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# # Example usage with your provided URL\n",
    "# url = 'https://www.figma.com/design/OQwKrUjzZo7yNxlEXAgiIl/SEA-Test-Module-1?node-id=0-1&node-type=canvas&t=BKlbwkqXlDCJbIXI-0'\n",
    "# file_name = get_file_name_from_url(url)\n",
    "\n",
    "# print(f\"File Name: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the appropriate header tag based on font size\n",
    "def determine_header_tag(font_size):\n",
    "    if font_size >= 32:\n",
    "        return 'h1'\n",
    "    elif 24 <= font_size < 32:\n",
    "        return 'h2'\n",
    "    elif 20 <= font_size < 24:\n",
    "        return 'h3'\n",
    "    elif 16 <= font_size < 20:\n",
    "        return 'h4'\n",
    "    elif 14 <= font_size < 16:\n",
    "        return 'h5'\n",
    "    else:\n",
    "        return 'h6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the template type based on frame content\n",
    "def determine_template_type(frame):\n",
    "    contains_text = False\n",
    "    contains_image = False\n",
    "    label_like_text_only = True  # Assume the text is a label by default\n",
    "\n",
    "    for node in frame['children']:\n",
    "        if node['type'] == 'TEXT':\n",
    "            text = node.get('characters', '').strip()\n",
    "            # Check if the text is more than a label (like image_1 or graph_1)\n",
    "            if re.search(r'image_\\d+|graph_\\d+', text):\n",
    "                continue  # Ignore label-like text\n",
    "            elif len(text) > 0:  # Consider non-empty and non-label text as real text\n",
    "                contains_text = True  # Regular text, not a label\n",
    "                label_like_text_only = False\n",
    "        if node['type'] in ['IMAGE', 'VECTOR', 'RECTANGLE']:  # 'VECTOR' or 'RECTANGLE' might be used for images\n",
    "            contains_image = True\n",
    "\n",
    "    # determine template type based on whether the frame contains real text or just label-like text\n",
    "    if contains_image and label_like_text_only:  # Only label-like text and image\n",
    "        return 'Photo'\n",
    "    elif contains_image and contains_text:\n",
    "        return 'Text-Image'\n",
    "    elif contains_text and not contains_image:\n",
    "        return 'Text'\n",
    "    else:\n",
    "        return 'Unknown'  # In case neither text nor image is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch image and graphic URL from GitHub\n",
    "def get_image_url(text, section_name, extension='.png'):\n",
    "    # Check if the text contains image or graph labels, and fetch the corresponding URL\n",
    "    image_match = re.search(r'image_(\\d+)', text)\n",
    "    graph_match = re.search(r'graph_(\\d+)', text)\n",
    "    \n",
    "    if image_match:\n",
    "        return f'{GITHUB_BASE_URL}Images/image_{image_match.group(1)}{extension}'\n",
    "    elif graph_match:\n",
    "        return f'{GITHUB_BASE_URL}Graphics/{section_name}/graph_{graph_match.group(1)}{extension}'\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# # Test Case\n",
    "# \"\"\"\n",
    "# The input is a string containing references to images or graphs (e.g., \"image_1\" or \"graph_2\"), along with a section number  \n",
    "# The function generates a URL for that image or graph.\n",
    "# Example input: Text with image reference, Text with graph reference, Text without any reference\n",
    "# Expected output: A Github URL for the image/graph or None if no reference is found\n",
    "# \"\"\"\n",
    "# # Example test\n",
    "# text_with_image = 'image_1'\n",
    "# text_with_graph = 'graph_2'\n",
    "# text_with_no_image_or_graph = 'No references here'\n",
    "\n",
    "# GITHUB_BASE_URL = 'https://raw.githubusercontent.com/UNDP-Data/dsc-energy-academy-pipeline/main/03_Inputs/'\n",
    "\n",
    "# print(f\"Image URL: {get_image_url(text_with_image, 1)}\") # Expected output: URL pointing to image_1.png'\n",
    "# print(f\"Graph URL: {get_image_url(text_with_graph, 1)}\") # Expected output: URL pointing to graph_2.png\n",
    "# print(f\"No image or graph URL found on the frame: {get_image_url(text_with_no_image_or_graph, 1)}\") # Expected output: None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a frame and extract relevant information\n",
    "def process_frame(frame, section_name, chapter_name, lesson_number, column_number):\n",
    "    if 'absoluteBoundingBox' not in frame:\n",
    "        print(f\"Warning: 'absoluteBoundingBox' missing for frame '{frame.get('name', 'Unnamed')}'. Skipping this frame.\")\n",
    "        return None\n",
    "    \n",
    "    template_type = determine_template_type(frame)\n",
    "    \n",
    "    frame_data = {\n",
    "        'Section': section_name,\n",
    "        'Chapter': chapter_name,\n",
    "        'Lesson': lesson_number,\n",
    "        'Frame Title': frame['name'],\n",
    "        'Template Type': template_type,\n",
    "        'Column': column_number,\n",
    "        'Text': '',\n",
    "        'x': frame['absoluteBoundingBox']['x'],\n",
    "        'y': frame['absoluteBoundingBox']['y'],\n",
    "        'image_url': None\n",
    "    }\n",
    "\n",
    "    for node in frame['children']:\n",
    "        if node['type'] == 'TEXT':\n",
    "            font_size = node.get('style', {}).get('fontSize', 14)  # Default to 14 if no fontSize is found\n",
    "            header_tag = determine_header_tag(font_size)\n",
    "            text = node['characters']\n",
    "            frame_data['Text'] += f'<{header_tag}>{text}</{header_tag}>'\n",
    "\n",
    "            # Add the image/graphic URL if image_[number] or graph_[number] is found\n",
    "            image_url = get_image_url(text, section_name)\n",
    "            if image_url:\n",
    "                frame_data['image_url'] = image_url\n",
    "    \n",
    "    return frame_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract frames from lessons\n",
    "def extract_frames(nodes, section_name, chapter_name, lesson_number):\n",
    "    frames = []\n",
    "    column_number = 1  # Track the column within each lesson\n",
    "\n",
    "    for node in nodes:\n",
    "        if node['type'] == 'FRAME':\n",
    "            processed_frame = process_frame(node, section_name, chapter_name, lesson_number, column_number)\n",
    "            if processed_frame:\n",
    "                frames.append(processed_frame)\n",
    "                column_number += 1\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dynamically assign lessons based on similar y-values (rows)\n",
    "def assign_lessons_by_row(frames, y_threshold=500):  # You can adjust the y_threshold\n",
    "    if not frames:\n",
    "        return frames\n",
    "\n",
    "    # Sort frames by their y-position first, then by x-position\n",
    "    frames.sort(key=lambda f: (f['absoluteBoundingBox']['y'], f['absoluteBoundingBox']['x']))\n",
    "\n",
    "    lesson_number = 1\n",
    "    last_y = frames[0]['absoluteBoundingBox']['y']\n",
    "    \n",
    "    for frame in frames:\n",
    "        current_y = frame['absoluteBoundingBox']['y']\n",
    "\n",
    "        # If the vertical difference between frames is larger than the threshold, start a new lesson\n",
    "        if abs(current_y - last_y) > y_threshold:\n",
    "            lesson_number += 1\n",
    "\n",
    "        # Assign the lesson number\n",
    "        frame['Lesson'] = lesson_number\n",
    "\n",
    "        # Update last_y to the current frame's y-position\n",
    "        last_y = current_y\n",
    "    \n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract chapters and lessons dynamically based on vertical spacing\n",
    "def extract_chapters_and_lessons(document_children):\n",
    "    chapters = []\n",
    "    \n",
    "    for canvas_node in document_children:\n",
    "        if canvas_node['type'] == 'CANVAS':\n",
    "            for chapter_node in canvas_node['children']:\n",
    "                if 'Chapter' in chapter_node['name']:  # Detect chapters by their name (e.g., \"Chapter 1\", \"Chapter 2\")\n",
    "                    chapter_name = chapter_node['name']\n",
    "                    all_frames = [frame for frame in chapter_node['children'] if frame['type'] == 'FRAME' and not frame['name'].startswith('Vector')]\n",
    "\n",
    "                    # Assign lessons based on vertical spacing\n",
    "                    frames_with_lessons = assign_lessons_by_row(all_frames, y_threshold=500)\n",
    "\n",
    "                    # Group frames by their lesson number\n",
    "                    lessons = []\n",
    "                    current_lesson = []\n",
    "                    current_lesson_number = frames_with_lessons[0]['Lesson']\n",
    "                    \n",
    "                    for frame in frames_with_lessons:\n",
    "                        if frame['Lesson'] != current_lesson_number:\n",
    "                            lessons.append(current_lesson)\n",
    "                            current_lesson = []\n",
    "                            current_lesson_number = frame['Lesson']\n",
    "                        \n",
    "                        current_lesson.append(frame)\n",
    "\n",
    "                    # Append the last lesson\n",
    "                    if current_lesson:\n",
    "                        lessons.append(current_lesson)\n",
    "\n",
    "                    # Add chapter and its associated lessons to the list\n",
    "                    chapters.append({\n",
    "                        'chapter_name': chapter_name,\n",
    "                        'lessons': lessons\n",
    "                    })\n",
    "\n",
    "    return chapters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the frames data to a CSV file\n",
    "def save_to_csv(frames, section_name, chapter_name, lesson_number, filename):\n",
    "    # Sort frames by y-position if 'y' exists, otherwise fallback to unsorted\n",
    "    frames_with_y = [frame for frame in frames if 'y' in frame]\n",
    "    frames_without_y = [frame for frame in frames if 'y' not in frame]\n",
    "    \n",
    "    # Sort frames with 'y' by y-position\n",
    "    frames_with_y.sort(key=lambda frame: frame['y'])\n",
    "    \n",
    "    # Combine frames (sorted ones with 'y' first, then those without 'y')\n",
    "    sorted_frames = frames_with_y + frames_without_y\n",
    "    \n",
    "    # Assign the correct column number after sorting\n",
    "    for i, frame in enumerate(sorted_frames):\n",
    "        frame['Column'] = i + 1\n",
    "        frame.pop('x', None)  # Remove 'x' after sorting\n",
    "        frame.pop('y', None)  # Remove 'y' after sorting if it exists\n",
    "\n",
    "    # Define folder path for the current Figma file (section) and chapter\n",
    "    csv_folder = os.path.join('..', '01_Results', f'{section_name}')\n",
    "    chapter_folder = os.path.join(csv_folder, f'{chapter_name}')\n",
    "    \n",
    "    os.makedirs(chapter_folder, exist_ok=True)  # Ensure the folder structure exists\n",
    "    \n",
    "    # Full path to the CSV file (e.g., Lesson_1.csv, Lesson_2.csv)\n",
    "    csv_path = os.path.join(chapter_folder, filename)\n",
    "    \n",
    "    # Open the CSV file for writing\n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=['Section', 'Lesson', 'Chapter', 'Frame Title', 'Template Type', 'Column', 'Text', 'image_url'])\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write each frame's data to the CSV file\n",
    "        for frame in sorted_frames:\n",
    "            writer.writerow(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the frames data to JSON files\n",
    "def save_to_json(frames, section_name, chapter_name, lesson_number, filename):\n",
    "    # Sort frames by y-position if 'y' exists, otherwise fallback to unsorted\n",
    "    frames_with_y = [frame for frame in frames if 'y' in frame]\n",
    "    frames_without_y = [frame for frame in frames if 'y' not in frame]\n",
    "    \n",
    "    # Sort frames with 'y' by y-position\n",
    "    frames_with_y.sort(key=lambda frame: frame['y'])\n",
    "    \n",
    "    # Combine frames (sorted ones with 'y' first, then those without 'y')\n",
    "    sorted_frames = frames_with_y + frames_without_y\n",
    "\n",
    "    # Assign the correct column number after sorting\n",
    "    for i, frame in enumerate(sorted_frames):\n",
    "        frame['Column'] = i + 1\n",
    "        frame.pop('x', None)  # Remove 'x' after sorting\n",
    "        frame.pop('y', None)  # Remove 'y' after sorting if it exists\n",
    "\n",
    "    # Define folder path for the current Figma file (section) and chapter\n",
    "    json_folder = os.path.join('..', '00_API', f'{section_name}')\n",
    "    chapter_folder = os.path.join(json_folder, f'{chapter_name}')\n",
    "    \n",
    "    os.makedirs(chapter_folder, exist_ok=True)  # Ensure the folder structure exists\n",
    "    \n",
    "    # Full path to the JSON file (e.g., Lesson_1.json, Lesson_2.json)\n",
    "    json_path = os.path.join(chapter_folder, filename)\n",
    "    \n",
    "    # Convert the frames list to a JSON structure and save to file\n",
    "    with open(json_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(sorted_frames, json_file, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to fecth data adding delay and retry logic for handling rate limits and avoiding timeouts\n",
    "\n",
    "def fetch_file_data(file_key):\n",
    "    max_retries = 5\n",
    "    retry_count = 0\n",
    "    delay_between_retries = 10  # Delay of 10 seconds between retries\n",
    "\n",
    "    while retry_count < max_retries:\n",
    "        response = requests.get(FIGMA_API_URL_TEMPLATE.format(file_key), headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # If the request is successful, return the data\n",
    "            return response.json()\n",
    "        \n",
    "        elif response.status_code == 429:  # Rate limit hit\n",
    "            print(\"Rate limit hit. Waiting for rate limit reset...\")\n",
    "            retry_after = int(response.headers.get('Retry-After', delay_between_retries))\n",
    "            time.sleep(retry_after)\n",
    "            retry_count += 1\n",
    "        \n",
    "        else:\n",
    "            print(f\"Error: Failed to fetch data for file key {file_key}. Status code: {response.status_code}\")\n",
    "            retry_count += 1\n",
    "            time.sleep(delay_between_retries)\n",
    "\n",
    "    print(f\"Max retries reached for file {file_key}. Skipping...\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Main Processing Function </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_keys = ['XN57QSSgnI4exbB2OTK1QM'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Main processing function\n",
    "def process_figma_files(file_keys):\n",
    "    for file_key in file_keys:\n",
    "        file_data = fetch_file_data(file_key)\n",
    "        if file_data and 'name' in file_data:\n",
    "            section_name = file_data['name']  # Retrieve file name (e.g., \"Module 1\")\n",
    "        else:\n",
    "            print(f\"Error: Could not retrieve file name for file key: {file_key}\")\n",
    "            continue\n",
    "\n",
    "        if file_data and 'document' in file_data:\n",
    "            document_children = file_data['document']['children']\n",
    "\n",
    "            # Extract chapters and lessons dynamically based on vertical spacing\n",
    "            chapters = extract_chapters_and_lessons(document_children)\n",
    "\n",
    "            # Process each chapter and its lessons\n",
    "            for chapter in chapters:\n",
    "                chapter_name = chapter['chapter_name']  # Example: \"Chapter 1\"\n",
    "                lessons = chapter['lessons']\n",
    "\n",
    "                # Process each lesson\n",
    "                for lesson_number, lesson_frames in enumerate(lessons, start=1):\n",
    "                    frames = extract_frames(lesson_frames, section_name, chapter_name, lesson_number)\n",
    "                    \n",
    "                    # Save CSV and JSON for each lesson\n",
    "                    csv_filename = f'Lesson_{lesson_number}.csv'\n",
    "                    json_filename = f'Lesson_{lesson_number}.json'\n",
    "\n",
    "                    save_to_csv(frames, section_name, chapter_name, lesson_number, csv_filename)\n",
    "                    print(f\"CSV file '{csv_filename}' has been saved in {chapter_name} 01_Results folder\")\n",
    "\n",
    "                    save_to_json(frames, section_name, chapter_name, lesson_number, json_filename)\n",
    "                    print(f\"JSON file '{json_filename}' has been saved in {chapter_name} 00_API folder\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Error: 'document' key not found in file {file_key}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Lesson_1.csv' has been saved in Chapter 3 01_Results folder\n",
      "JSON file 'Lesson_1.json' has been saved in Chapter 3 00_API folder\n",
      "CSV file 'Lesson_2.csv' has been saved in Chapter 3 01_Results folder\n",
      "JSON file 'Lesson_2.json' has been saved in Chapter 3 00_API folder\n",
      "CSV file 'Lesson_1.csv' has been saved in Chapter 2 01_Results folder\n",
      "JSON file 'Lesson_1.json' has been saved in Chapter 2 00_API folder\n",
      "CSV file 'Lesson_2.csv' has been saved in Chapter 2 01_Results folder\n",
      "JSON file 'Lesson_2.json' has been saved in Chapter 2 00_API folder\n",
      "CSV file 'Lesson_1.csv' has been saved in Chapter 1 01_Results folder\n",
      "JSON file 'Lesson_1.json' has been saved in Chapter 1 00_API folder\n",
      "CSV file 'Lesson_2.csv' has been saved in Chapter 1 01_Results folder\n",
      "JSON file 'Lesson_2.json' has been saved in Chapter 1 00_API folder\n"
     ]
    }
   ],
   "source": [
    "# the main function with the list of file keys\n",
    "process_figma_files(file_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
