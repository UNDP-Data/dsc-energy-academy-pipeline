{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install PyGithub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process multiple files sequentially & Extract images and graphics URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file for Module 1:\n",
      "Frames data has been exported to figma_frames_XN57QSSgnI4exbB2OTK1QM.csv\n",
      "Frames data has been exported to figma_frames_XN57QSSgnI4exbB2OTK1QM.json\n",
      "Processing file for Module 2:\n",
      "Frames data has been exported to figma_frames_5cH2oMyNQPZ1w9fUPM9Mfe.csv\n",
      "Frames data has been exported to figma_frames_5cH2oMyNQPZ1w9fUPM9Mfe.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import time  # For adding delays between requests\n",
    "\n",
    "API_TOKEN = 'add figma token'\n",
    "FILE_KEYS = ['XN57QSSgnI4exbB2OTK1QM/MODULE1', '5cH2oMyNQPZ1w9fUPM9Mfe/MODULE2']  # Ensure MODULE is part of the file key or name\n",
    "\n",
    "# Figma API URL template\n",
    "FIGMA_API_URL_TEMPLATE = 'https://api.figma.com/v1/files/{}'\n",
    "\n",
    "# Headers for the API request\n",
    "headers = {\n",
    "    'X-Figma-Token': API_TOKEN\n",
    "}\n",
    "\n",
    "# Base URL for the GitHub repository to fetch images and graphics\n",
    "GITHUB_BASE_URL = 'https://raw.githubusercontent.com/UNDP-Data/dsc-energy-academy-pipeline/main/03_Inputs/'\n",
    "\n",
    "# Function to determine the module (section) number from the file name or URL (e.g., MODULE1 -> 1)\n",
    "def get_section_number(file_name):\n",
    "    match = re.search(r'MODULE(\\d+)', file_name, re.IGNORECASE)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Function to determine the appropriate header tag based on font size\n",
    "def determine_header_tag(font_size):\n",
    "    if font_size >= 32:\n",
    "        return 'h1'\n",
    "    elif 24 <= font_size < 32:\n",
    "        return 'h2'\n",
    "    elif 20 <= font_size < 24:\n",
    "        return 'h3'\n",
    "    elif 16 <= font_size < 20:\n",
    "        return 'h4'\n",
    "    elif 14 <= font_size < 16:\n",
    "        return 'h5'\n",
    "    else:\n",
    "        return 'h6'\n",
    "\n",
    "# Function to determine the template type based on frame content\n",
    "def determine_template_type(frame):\n",
    "    contains_text = False\n",
    "    contains_image = False\n",
    "    label_like_text_only = True  # Assume the text is a label by default\n",
    "\n",
    "    for node in frame['children']:\n",
    "        if node['type'] == 'TEXT':\n",
    "            text = node.get('characters', '').strip()\n",
    "            # Check if the text is more than a label (like image_1 or graph_1)\n",
    "            if re.search(r'image_\\d+|graph_\\d+', text):\n",
    "                continue  # Ignore label-like text\n",
    "            elif len(text) > 0:  # Consider non-empty and non-label text as real text\n",
    "                contains_text = True  # Regular text, not a label\n",
    "                label_like_text_only = False\n",
    "        if node['type'] in ['IMAGE', 'VECTOR', 'RECTANGLE']:  # 'VECTOR' or 'RECTANGLE' might be used for images\n",
    "            contains_image = True\n",
    "\n",
    "    # Now determine template type based on whether the frame contains real text or just label-like text\n",
    "    if contains_image and label_like_text_only:  # Only label-like text and image\n",
    "        return 'Photo'\n",
    "    elif contains_image and contains_text:\n",
    "        return 'Text-Image'\n",
    "    elif contains_text and not contains_image:\n",
    "        return 'Text'\n",
    "    else:\n",
    "        return 'Unknown'  # In case neither text nor image is found\n",
    "\n",
    "\n",
    "# Function to process a frame and extract relevant information\n",
    "def process_frame(frame, section_number, subsection_number=None):\n",
    "    # Check if 'absoluteBoundingBox' exists\n",
    "    if 'absoluteBoundingBox' not in frame:\n",
    "        print(f\"Warning: 'absoluteBoundingBox' missing for frame '{frame.get('name', 'Unnamed')}'. Skipping this frame.\")\n",
    "        return None  # Return None to indicate skipping this frame\n",
    "    \n",
    "    # Determine template type (Photo/Text or Text-Image) based on content\n",
    "    template_type = determine_template_type(frame)\n",
    "    \n",
    "    frame_data = {\n",
    "        'Section': section_number,\n",
    "        'Subsection': subsection_number, \n",
    "        'Section Title': frame['name'],  \n",
    "        'Template Type': template_type,\n",
    "        'Column': 0,  \n",
    "        'Text': '',  \n",
    "        'x': frame['absoluteBoundingBox']['x'],  # Capture the x position for sorting\n",
    "        'y': frame['absoluteBoundingBox']['y'],  # Capture the y position for sorting\n",
    "        'image_url': None  # Placeholder for the image URL\n",
    "    }\n",
    "\n",
    "    # Process all nodes within the frame\n",
    "    for node in frame['children']:\n",
    "        if node['type'] == 'TEXT':\n",
    "            font_size = node.get('style', {}).get('fontSize', 14)  # Default to 14 if no fontSize is found\n",
    "            header_tag = determine_header_tag(font_size)\n",
    "            text = node['characters']\n",
    "            # Concatenate text with the appropriate header tags\n",
    "            frame_data['Text'] += f'<{header_tag}>{text}</{header_tag}>'\n",
    "\n",
    "            # Add the image/graphic URL if image_[number] or graph_[number] is found\n",
    "            image_url = get_image_url(text, section_number)\n",
    "            if image_url:\n",
    "                frame_data['image_url'] = image_url\n",
    "    \n",
    "    return frame_data\n",
    "\n",
    "\n",
    "# Function to recursively extract frames from the file data and assign subsections\n",
    "def extract_frames(nodes, section_number=1):\n",
    "    frames = []  # Initialize a new list for each call to avoid data mix-up\n",
    "    \n",
    "    # Extract all frames in a flat list\n",
    "    for node in nodes:\n",
    "        if node['type'] == 'FRAME':\n",
    "            # Process the frame with the current section and default subsection number\n",
    "            processed_frame = process_frame(node, section_number)\n",
    "            if processed_frame:  # Only add if the frame was successfully processed\n",
    "                frames.append(processed_frame)\n",
    "        \n",
    "        # Recursively process child nodes (if any)\n",
    "        if 'children' in node:\n",
    "            frames.extend(extract_frames(node['children'], section_number))\n",
    "\n",
    "    return frames\n",
    "\n",
    "# Function to dynamically assign subsections based on similar y-values (rows)\n",
    "def assign_subsections_by_row(frames, y_threshold=100):\n",
    "    if not frames:\n",
    "        return frames\n",
    "\n",
    "    # Sort frames by their y-position first, then by x-position\n",
    "    frames.sort(key=lambda f: (f['y'], f['x']))\n",
    "\n",
    "    subsection_number = 1\n",
    "    last_y = frames[0]['y']\n",
    "    \n",
    "    for frame in frames:\n",
    "        # If the vertical difference between frames is larger than the threshold, start a new subsection\n",
    "        if abs(frame['y'] - last_y) > y_threshold:\n",
    "            subsection_number += 1\n",
    "\n",
    "        # Assign the subsection number\n",
    "        frame['Subsection'] = subsection_number\n",
    "\n",
    "        # Update last_y to the current frame's y-position\n",
    "        last_y = frame['y']\n",
    "    \n",
    "    return frames\n",
    "\n",
    "# Function to fetch image and graphic URL from GitHub\n",
    "def get_image_url(text, section_number, extension='.png'):\n",
    "    # Check if the text contains image or graph labels, and fetch the corresponding URL\n",
    "    image_match = re.search(r'image_(\\d+)', text)\n",
    "    graph_match = re.search(r'graph_(\\d+)', text)\n",
    "    \n",
    "    if image_match:\n",
    "        return f'{GITHUB_BASE_URL}Images/image_{image_match.group(1)}{extension}'\n",
    "    elif graph_match:\n",
    "        return f'{GITHUB_BASE_URL}Graphics/Module{section_number}/graph_{graph_match.group(1)}{extension}'\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# Function to save the frames data to a CSV file\n",
    "def save_to_csv(frames, filename):\n",
    "    # Assign the correct column number after sorting\n",
    "    for i, frame in enumerate(frames):\n",
    "        frame['Column'] = i + 1\n",
    "        frame.pop('x', None)  # Remove 'x' after sorting\n",
    "        frame.pop('y', None)  # Remove 'y' after sorting\n",
    "\n",
    "    # Specify the CSV column headers\n",
    "    csv_columns = ['Section', 'Subsection', 'Section Title', 'Template Type', 'Column', 'Text', 'image_url']\n",
    "    \n",
    "    # Define the path to save the CSV file in the \"01_Results\" folder\n",
    "    results_folder = os.path.join('..', '01_Results')\n",
    "    os.makedirs(results_folder, exist_ok=True)  # Ensure the folder exists\n",
    "\n",
    "    # Full path to the CSV file\n",
    "    csv_path = os.path.join(results_folder, filename)\n",
    "    \n",
    "    # Open the CSV file for writing\n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write each frame's data to the CSV file\n",
    "        for frame in frames:\n",
    "            writer.writerow(frame)\n",
    "\n",
    "# Function to save the frames data to JSON files\n",
    "def save_to_json(frames, filename):\n",
    "    # Assign the correct column number after sorting\n",
    "    for i, frame in enumerate(frames):\n",
    "        frame['Column'] = i + 1\n",
    "        frame.pop('x', None)  # Remove 'x' after sorting\n",
    "        frame.pop('y', None)  # Remove 'y' after sorting\n",
    "    \n",
    "    # Define the path to save the JSON file in the \"00_API\" folder\n",
    "    api_folder = os.path.join('..', '00_API')\n",
    "    os.makedirs(api_folder, exist_ok=True)  # Ensure the folder exists\n",
    "\n",
    "\n",
    "    # Full path to the JSON file\n",
    "    json_path = os.path.join(api_folder, filename)                   \n",
    "\n",
    "    # Convert the frames list to a JSON structure and save to file\n",
    "    with open(json_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(frames, json_file, indent=4, ensure_ascii=False)\n",
    "        \n",
    "# Adding delay and retry logic for handling rate limits and avoiding timeouts\n",
    "def fetch_file_data(file_key):\n",
    "    max_retries = 5\n",
    "    retry_count = 0\n",
    "    delay_between_retries = 10  # delay of 10 seconds\n",
    "    while retry_count < max_retries:\n",
    "        response = requests.get(FIGMA_API_URL_TEMPLATE.format(file_key.split('/')[0]), headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        elif response.status_code == 429:  # Rate limit hit, Figma API returns 429\n",
    "            print(\"Rate limit hit. Waiting for rate limit reset...\")\n",
    "            retry_after = int(response.headers.get('Retry-After', delay_between_retries))\n",
    "            time.sleep(retry_after)\n",
    "            retry_count += 1\n",
    "        else:\n",
    "            print(f\"Error: Failed to fetch data for file key {file_key}. Status code: {response.status_code}\")\n",
    "            retry_count += 1\n",
    "            time.sleep(delay_between_retries)\n",
    "    print(f\"Max retries reached for file {file_key}. Skipping...\")\n",
    "    return None\n",
    "\n",
    "# Main processing function with sequential fetching and retry handling\n",
    "def process_figma_files(file_keys):\n",
    "    for file_key in file_keys:\n",
    "        section_number = get_section_number(file_key) or 0\n",
    "        print(f\"Processing file for Module {section_number}:\")\n",
    "\n",
    "        file_data = fetch_file_data(file_key)\n",
    "        if file_data and 'document' in file_data:\n",
    "            frames = extract_frames(file_data['document']['children'], section_number)\n",
    "            \n",
    "            # Assign subsections based on rows (y-coordinate differences)\n",
    "            frames = assign_subsections_by_row(frames, y_threshold=100)\n",
    "\n",
    "            csv_filename = f'figma_frames_{file_key.split(\"/\")[0]}.csv'\n",
    "            json_filename = f'figma_frames_{file_key.split(\"/\")[0]}.json'\n",
    "\n",
    "            save_to_csv(frames, csv_filename)\n",
    "            print(f\"Frames data has been exported to {csv_filename}\")\n",
    "\n",
    "            save_to_json(frames, json_filename)\n",
    "            print(f\"Frames data has been exported to {json_filename}\")\n",
    "        else:\n",
    "            print(f\"Warning: 'document' key not found in file {file_key}. Skipping.\")\n",
    "\n",
    "# Execute the main function with the list of file keys\n",
    "process_figma_files(FILE_KEYS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
